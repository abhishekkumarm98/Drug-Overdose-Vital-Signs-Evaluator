{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import time, os, joblib\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"],"metadata":{"id":"W2_Y273Q-XMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install catboost"],"metadata":{"id":"uK2o7MwA-XXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.ensemble import HistGradientBoostingClassifier"],"metadata":{"id":"4j5ahwYCFF_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_hdf(\"PatientDataClass_25Hz_88_99_feats_44_lag.h5\")\n","df.shape"],"metadata":{"id":"mHGj7LA52JhO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708646720248,"user_tz":300,"elapsed":4835,"user":{"displayName":"AbhishekKumar Mishra","userId":"11586003993107719833"}},"outputId":"c064c1a0-2c5f-411b-a9cb-a785449b994c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((401469, 44),)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"id":"KHFchHJ-2ldq","executionInfo":{"status":"ok","timestamp":1708646721232,"user_tz":300,"elapsed":999,"user":{"displayName":"AbhishekKumar Mishra","userId":"11586003993107719833"}},"outputId":"c3fb534b-d049-425a-9e56-c3572828d0a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   time_stamp_corrected  time_stamp       red        ir  red_amplitude  \\\n","0               5.17310  2098.60374  232406.0  245777.0           99.0   \n","1               5.21447  2098.64511  232370.0  245766.0           99.0   \n","2               5.42132  2098.85196  232236.0  245709.0           99.0   \n","3               5.50406  2098.93470  232181.0  245686.0           99.0   \n","4               5.54543  2098.97607  232121.0  245657.0           99.0   \n","\n","   ir_amplitude  accel_x  accel_y  accel_z  gyro_pitch  ...  \\\n","0          72.0   0.3459   0.5294   0.8017       -1.61  ...   \n","1          72.0   0.3494   0.5294   0.8022       -1.33  ...   \n","2          72.0   0.3440   0.5314   0.8008       -1.33  ...   \n","3          72.0   0.3459   0.5299   0.8008       -1.68  ...   \n","4          72.0   0.3445   0.5319   0.7998       -1.40  ...   \n","\n","   amp_inhale_lag_125  amp_exhale_lag_125  dur_inhale_lag_125  \\\n","0            3.975327           -3.013573                1.88   \n","1            3.975327           -3.013573                1.88   \n","2            3.975327           -3.013573                1.88   \n","3            3.975327           -3.013573                1.88   \n","4            3.975327           -3.013573                1.88   \n","\n","   dur_exhale_lag_125  rr_lag_250  amp_inhale_lag_250  amp_exhale_lag_250  \\\n","0                1.64   15.874008             2.86174           -3.260328   \n","1                1.64   15.874008             2.86174           -3.260328   \n","2                1.64   15.874008             2.86174           -3.260328   \n","3                1.64   15.874008             2.86174           -3.260328   \n","4                1.64   15.874008             2.86174           -3.260328   \n","\n","   dur_inhale_lag_250  dur_exhale_lag_250         R  \n","0                2.28                2.28  1.021095  \n","1                2.28                2.28  1.022678  \n","2                2.28                2.28  1.020785  \n","3                2.28                2.28  1.020648  \n","4                2.28                2.28  1.020430  \n","\n","[5 rows x 44 columns]"],"text/html":["\n","  <div id=\"df-3768805c-0891-4c88-af94-086f5e187c13\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time_stamp_corrected</th>\n","      <th>time_stamp</th>\n","      <th>red</th>\n","      <th>ir</th>\n","      <th>red_amplitude</th>\n","      <th>ir_amplitude</th>\n","      <th>accel_x</th>\n","      <th>accel_y</th>\n","      <th>accel_z</th>\n","      <th>gyro_pitch</th>\n","      <th>...</th>\n","      <th>amp_inhale_lag_125</th>\n","      <th>amp_exhale_lag_125</th>\n","      <th>dur_inhale_lag_125</th>\n","      <th>dur_exhale_lag_125</th>\n","      <th>rr_lag_250</th>\n","      <th>amp_inhale_lag_250</th>\n","      <th>amp_exhale_lag_250</th>\n","      <th>dur_inhale_lag_250</th>\n","      <th>dur_exhale_lag_250</th>\n","      <th>R</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.17310</td>\n","      <td>2098.60374</td>\n","      <td>232406.0</td>\n","      <td>245777.0</td>\n","      <td>99.0</td>\n","      <td>72.0</td>\n","      <td>0.3459</td>\n","      <td>0.5294</td>\n","      <td>0.8017</td>\n","      <td>-1.61</td>\n","      <td>...</td>\n","      <td>3.975327</td>\n","      <td>-3.013573</td>\n","      <td>1.88</td>\n","      <td>1.64</td>\n","      <td>15.874008</td>\n","      <td>2.86174</td>\n","      <td>-3.260328</td>\n","      <td>2.28</td>\n","      <td>2.28</td>\n","      <td>1.021095</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.21447</td>\n","      <td>2098.64511</td>\n","      <td>232370.0</td>\n","      <td>245766.0</td>\n","      <td>99.0</td>\n","      <td>72.0</td>\n","      <td>0.3494</td>\n","      <td>0.5294</td>\n","      <td>0.8022</td>\n","      <td>-1.33</td>\n","      <td>...</td>\n","      <td>3.975327</td>\n","      <td>-3.013573</td>\n","      <td>1.88</td>\n","      <td>1.64</td>\n","      <td>15.874008</td>\n","      <td>2.86174</td>\n","      <td>-3.260328</td>\n","      <td>2.28</td>\n","      <td>2.28</td>\n","      <td>1.022678</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.42132</td>\n","      <td>2098.85196</td>\n","      <td>232236.0</td>\n","      <td>245709.0</td>\n","      <td>99.0</td>\n","      <td>72.0</td>\n","      <td>0.3440</td>\n","      <td>0.5314</td>\n","      <td>0.8008</td>\n","      <td>-1.33</td>\n","      <td>...</td>\n","      <td>3.975327</td>\n","      <td>-3.013573</td>\n","      <td>1.88</td>\n","      <td>1.64</td>\n","      <td>15.874008</td>\n","      <td>2.86174</td>\n","      <td>-3.260328</td>\n","      <td>2.28</td>\n","      <td>2.28</td>\n","      <td>1.020785</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.50406</td>\n","      <td>2098.93470</td>\n","      <td>232181.0</td>\n","      <td>245686.0</td>\n","      <td>99.0</td>\n","      <td>72.0</td>\n","      <td>0.3459</td>\n","      <td>0.5299</td>\n","      <td>0.8008</td>\n","      <td>-1.68</td>\n","      <td>...</td>\n","      <td>3.975327</td>\n","      <td>-3.013573</td>\n","      <td>1.88</td>\n","      <td>1.64</td>\n","      <td>15.874008</td>\n","      <td>2.86174</td>\n","      <td>-3.260328</td>\n","      <td>2.28</td>\n","      <td>2.28</td>\n","      <td>1.020648</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.54543</td>\n","      <td>2098.97607</td>\n","      <td>232121.0</td>\n","      <td>245657.0</td>\n","      <td>99.0</td>\n","      <td>72.0</td>\n","      <td>0.3445</td>\n","      <td>0.5319</td>\n","      <td>0.7998</td>\n","      <td>-1.40</td>\n","      <td>...</td>\n","      <td>3.975327</td>\n","      <td>-3.013573</td>\n","      <td>1.88</td>\n","      <td>1.64</td>\n","      <td>15.874008</td>\n","      <td>2.86174</td>\n","      <td>-3.260328</td>\n","      <td>2.28</td>\n","      <td>2.28</td>\n","      <td>1.020430</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 44 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3768805c-0891-4c88-af94-086f5e187c13')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3768805c-0891-4c88-af94-086f5e187c13 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3768805c-0891-4c88-af94-086f5e187c13');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6ed22713-752b-4bfd-bc1f-7363121c0f45\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ed22713-752b-4bfd-bc1f-7363121c0f45')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6ed22713-752b-4bfd-bc1f-7363121c0f45 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["columns_to_remove = [\"time_stamp_corrected\", \"time_stamp\", 'location', \"calibration\", 'category', 'patient_ID', 'SpO2(%)']"],"metadata":{"id":"uYxIVvnp38Kn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getNormalizedData(Type, X_train, X_val):\n","  \"\"\"\n","  args:\n","  Type: Minmax or Standard scaling technique\n","  X_train: Training data\n","  X_val: Validation data\n","\n","  return X_train_norm, X_val_norm, X_test_norm # Normalized\n","  \"\"\"\n","\n","  if Type == \"minmax\":\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    scaler.fit(X_train)\n","  elif Type == \"std\":\n","    scaler = StandardScaler()\n","    scaler.fit(X_train)\n","  else:\n","    scaler = RobustScaler()\n","    scaler.fit(X_train)\n","\n","  X_train_norm, X_val_norm = scaler.transform(X_train), scaler.transform(X_val)\n","\n","  return X_train_norm, X_val_norm, scaler"],"metadata":{"id":"z4_XU35e7Srv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mappingLabel(x):\n","    \"\"\"\n","    99-96 - Normal --> 2\n","    96-92 - Low    --> 1\n","    88-92 - Danger --> 0\n","    \"\"\"\n","\n","    if 88 <= x <= 91:\n","        return 0\n","    elif 92 <= x <= 95:\n","        return 1\n","    elif 96 <= x <= 99:\n","        return 2\n","\n","\n","def getAugmentedFeatures(df, cols_to_work):\n","\n","    patient_records = []\n","    for patient in df['patient_ID'].unique():\n","        patient_df = df[df['patient_ID'] == patient]\n","        patient_df = patient_df.sort_values('time_stamp').reset_index(drop=True)\n","\n","        # Features generation\n","        for col in cols_to_work:\n","            if col in ['amp_exhale_lag_125', 'amp_exhale_lag_250', 'amp_inhale_lag_125', 'amp_inhale_lag_250', 'dur_exhale_lag_125', 'dur_exhale_lag_250', 'dur_inhale_lag_125', 'dur_inhale_lag_250', 'rr_lag_125', 'rr_lag_250']:\n","                continue\n","            # Taking previous timestamp as a feature\n","            patient_df[col+'_shift_1' ] = patient_df[col].shift(periods=1)\n","            patient_df[col+'_shift_2' ] = patient_df[col].shift(periods=2)\n","            patient_df[col+'_shift_3' ] = patient_df[col].shift(periods=3)\n","\n","            patient_df = patient_df.fillna(0)\n","\n","            # Computing difference between feature at t and (t-1)\n","            patient_df[col+'_diff_1' ] = patient_df[col] - patient_df[col+'_shift_1' ]\n","            patient_df[col+'_diff_2' ] = patient_df[col] - patient_df[col+'_shift_2' ]\n","            patient_df[col+'_diff_3' ] = patient_df[col] - patient_df[col+'_shift_3' ]\n","\n","            # Computing difference w.r.t. mean, median, min, max\n","            patient_df[col+'_min' ] = patient_df[col] - patient_df[col].min()\n","            patient_df[col+'_max' ] = patient_df[col].max() - patient_df[col]\n","            patient_df[col+'_mean' ] = patient_df[col] - patient_df[col].mean()\n","            patient_df[col+'_median' ] = patient_df[col] - patient_df[col].median()\n","\n","        patient_records.append(patient_df)\n","\n","    patient_records = pd.concat(patient_records).reset_index(drop=True)\n","\n","    return patient_records"],"metadata":{"id":"P-tOrQ-tIgGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols_to_work = list(set(df.columns) - set(columns_to_remove + [\"SpO2(%)\", 'patient_ID']))\n","\n","df = getAugmentedFeatures(df, cols_to_work)\n","df['category'] = df['SpO2(%)'].apply(lambda row:mappingLabel(row))"],"metadata":{"id":"DhDq3AnrJX-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.mkdir(\"Tree\")"],"metadata":{"id":"AhqyOdtB_C05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"6-l-PitRXdCO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708646758271,"user_tz":300,"elapsed":32,"user":{"displayName":"AbhishekKumar Mishra","userId":"11586003993107719833"}},"outputId":"3bc732ad-2d6b-41cb-9006-4ff6609b0fda"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(401469, 325)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["label = df['category'].values\n","df = df.drop(columns_to_remove, axis=1)"],"metadata":{"id":"vwBQOvvvdsmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","    print(f\"Fold {i+1}:\")\n","\n","    tf.keras.backend.clear_session()\n","    tf.keras.utils.set_random_seed(42)\n","    tf.config.experimental.enable_op_determinism()\n","\n","    # norm = tf.keras.layers.Normalization(axis = -1)\n","    # norm.adapt(X_train)\n","\n","    # Building a Multi-layer perceptron model\n","    mlp = tf.keras.Sequential([\n","        tf.keras.layers.Dense(318, activation = \"relu\"),\n","        tf.keras.layers.Dropout(0.3),\n","        tf.keras.layers.Dense(512, activation = \"relu\"),\n","        tf.keras.layers.Dropout(0.3),\n","        tf.keras.layers.Dense(3, activation=\"softmax\")\n","        ])\n","\n","    mlp.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'], loss= \"sparse_categorical_crossentropy\")\n","\n","    X_train, X_val, y_train, y_val = train_test_split(df, label, test_size=0.10, stratify = label, random_state=i)\n","\n","    X_train_norm, X_val_norm, scaler = getNormalizedData(\"std\", X_train, X_val)\n","\n","    joblib.dump(scaler, os.getcwd() +\"/Tree/Scaler_fold_v_\" + str(i+1) + \".pkl\")\n","\n","\n","    print(f\"Training data: {X_train_norm.shape}\")\n","    print(f\"Validation data: {X_val_norm.shape}\")\n","    print()\n","\n","    print(f\"Training data y: {y_train.shape}\")\n","    print(f\"Validation data y: {y_val.shape}\")\n","    print()\n","\n","    classifiers_name = [\"MLP\", \"LogisticRegression\",\"RandomForest\", \"LGBM\", \"ExtraTrees\", \"XGBR\", \"CatBoost\", \"HistGradientBoosting\"]\n","\n","    lr = LogisticRegression()\n","    rf =  RandomForestClassifier(n_estimators = 100, criterion='gini', max_features = 'log2', max_depth=11, min_samples_split=2, random_state=42)\n","    lgbm = LGBMClassifier(n_estimators = 50, boosting_type = 'dart',max_depth = 11, num_leaves = 10, learning_rate=0.45, random_state =42)\n","    exrf = ExtraTreesClassifier(n_estimators = 50, criterion='gini', max_features = 'sqrt', max_depth=14, min_samples_split=12, random_state=42)\n","    xgb = XGBClassifier(n_estimators = 100, max_depth = 5, learning_rate=0.15, booster = 'gbtree', tree_method = 'auto',random_state=42)\n","    catbr = CatBoostClassifier(n_estimators = 50, learning_rate = 0.2, max_depth = 8, boosting_type = 'Plain',loss_function = \"MultiClass\",verbose = False, random_state = 42)\n","    hr = HistGradientBoostingClassifier(learning_rate=0.36, max_leaf_nodes=31, min_samples_leaf=20, max_iter=120, max_depth=3, random_state=42)\n","\n","    clfs = [mlp, lr, rf, lgbm, exrf, xgb, catbr, hr]\n","\n","    for ix,clf in enumerate(clfs):\n","      print(\"Training starts for\", end=\" \")\n","      print(classifiers_name[ix], \":\")\n","      strt_time = time.time()\n","      if classifiers_name[ix] == \"MLP\":\n","        clf.fit( X_train_norm, y_train, validation_data = (X_val_norm, y_val), epochs = 20, batch_size = 512, verbose =0,\n","                  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3, monitor = 'val_loss', mode = 'auto',restore_best_weights=True)])\n","\n","      clf.fit(X_train_norm, y_train)\n","      print(f\"Total time taken to train {classifiers_name[ix]} is {time.time() - strt_time} sec.\")\n","      print()\n","\n","      if classifiers_name[ix] == \"MLP\":\n","        pred_train = np.argmax(clf.predict(X_train_norm),1)\n","        pred_val = np.argmax(clf.predict(X_val_norm),1)\n","\n","      else:\n","        pred_train = clf.predict(X_train_norm)\n","        pred_val = clf.predict(X_val_norm)\n","\n","      print(\"Confusion Matrix for Training data:\")\n","      print(confusion_matrix(y_train, pred_train))\n","      print()\n","      print(\"Classification Report for Training data:\")\n","      print(classification_report(y_train, pred_train, digits=4))\n","      print()\n","      print()\n","      print(\"*\"*51)\n","      print()\n","      print()\n","      print(\"Confusion Matrix for Validation data:\")\n","      print(confusion_matrix(y_val, pred_val))\n","      print()\n","      print(\"Classification Report for Validation data:\")\n","      print(classification_report(y_val, pred_val, digits=4))\n","      print()\n","      print()"],"metadata":{"id":"hTamQE1xJYKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708652223291,"user_tz":300,"elapsed":5465040,"user":{"displayName":"AbhishekKumar Mishra","userId":"11586003993107719833"}},"outputId":"d4dd23a4-72dd-45af-feea-52ccb6b48d58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1:\n","Training data: (361322, 318)\n","Validation data: (40147, 318)\n","\n","Training data y: (361322,)\n","Validation data y: (40147,)\n","\n","Training starts for MLP :\n","11292/11292 [==============================] - 43s 4ms/step - loss: 0.4061 - accuracy: 0.8329\n","Total time taken to train MLP is 168.6224720478058 sec.\n","\n","11292/11292 [==============================] - 19s 2ms/step\n","1255/1255 [==============================] - 2s 1ms/step\n","Confusion Matrix for Training data:\n","[[116836   3451   1235]\n"," [  6350  97274  16300]\n"," [  1559   7969 110348]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9366    0.9614    0.9489    121522\n","           1     0.8949    0.8111    0.8510    119924\n","           2     0.8629    0.9205    0.8908    119876\n","\n","    accuracy                         0.8980    361322\n","   macro avg     0.8981    0.8977    0.8969    361322\n","weighted avg     0.8983    0.8980    0.8971    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12968   405   129]\n"," [  742 10706  1877]\n"," [  183   982 12155]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9334    0.9605    0.9467     13502\n","           1     0.8853    0.8035    0.8424     13325\n","           2     0.8583    0.9125    0.8846     13320\n","\n","    accuracy                         0.8924     40147\n","   macro avg     0.8924    0.8921    0.8912     40147\n","weighted avg     0.8925    0.8924    0.8915     40147\n","\n","\n","\n","Training starts for LogisticRegression :\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken to train LogisticRegression is 53.761338233947754 sec.\n","\n","Confusion Matrix for Training data:\n","[[93626 18351  9545]\n"," [24348 60573 35003]\n"," [15256 34094 70526]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7027    0.7704    0.7350    121522\n","           1     0.5360    0.5051    0.5201    119924\n","           2     0.6129    0.5883    0.6003    119876\n","\n","    accuracy                         0.6220    361322\n","   macro avg     0.6172    0.6213    0.6185    361322\n","weighted avg     0.6176    0.6220    0.6190    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[10513  1999   990]\n"," [ 2760  6684  3881]\n"," [ 1639  3784  7897]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7050    0.7786    0.7400     13502\n","           1     0.5361    0.5016    0.5183     13325\n","           2     0.6185    0.5929    0.6054     13320\n","\n","    accuracy                         0.6251     40147\n","   macro avg     0.6199    0.6244    0.6212     40147\n","weighted avg     0.6203    0.6251    0.6218     40147\n","\n","\n","\n","Training starts for RandomForest :\n","Total time taken to train RandomForest is 156.77908539772034 sec.\n","\n","Confusion Matrix for Training data:\n","[[113156   7529    837]\n"," [  7849 101414  10661]\n"," [  4041   9127 106708]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9049    0.9312    0.9178    121522\n","           1     0.8589    0.8457    0.8522    119924\n","           2     0.9027    0.8902    0.8964    119876\n","\n","    accuracy                         0.8892    361322\n","   macro avg     0.8889    0.8890    0.8888    361322\n","weighted avg     0.8889    0.8892    0.8890    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12630   786    86]\n"," [  878 11160  1287]\n"," [  443  1050 11827]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9053    0.9354    0.9201     13502\n","           1     0.8587    0.8375    0.8480     13325\n","           2     0.8960    0.8879    0.8919     13320\n","\n","    accuracy                         0.8872     40147\n","   macro avg     0.8867    0.8870    0.8867     40147\n","weighted avg     0.8868    0.8872    0.8868     40147\n","\n","\n","\n","Training starts for LGBM :\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.539883 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 74932\n","[LightGBM] [Info] Number of data points in the train set: 361322, number of used features: 317\n","[LightGBM] [Info] Start training from score -1.089674\n","[LightGBM] [Info] Start training from score -1.102911\n","[LightGBM] [Info] Start training from score -1.103312\n","Total time taken to train LGBM is 80.33590483665466 sec.\n","\n","Confusion Matrix for Training data:\n","[[112590   7427   1505]\n"," [ 12310  89934  17680]\n"," [  5136  13429 101311]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8658    0.9265    0.8951    121522\n","           1     0.8118    0.7499    0.7796    119924\n","           2     0.8408    0.8451    0.8430    119876\n","\n","    accuracy                         0.8409    361322\n","   macro avg     0.8395    0.8405    0.8392    361322\n","weighted avg     0.8396    0.8409    0.8395    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12538   783   181]\n"," [ 1296  9996  2033]\n"," [  571  1437 11312]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8704    0.9286    0.8986     13502\n","           1     0.8183    0.7502    0.7827     13325\n","           2     0.8363    0.8492    0.8427     13320\n","\n","    accuracy                         0.8431     40147\n","   macro avg     0.8417    0.8427    0.8413     40147\n","weighted avg     0.8418    0.8431    0.8416     40147\n","\n","\n","\n","Training starts for ExtraTrees :\n","Total time taken to train ExtraTrees is 51.21375894546509 sec.\n","\n","Confusion Matrix for Training data:\n","[[112574   7805   1143]\n"," [ 10114 100870   8940]\n"," [  5471   9522 104883]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8784    0.9264    0.9017    121522\n","           1     0.8534    0.8411    0.8472    119924\n","           2     0.9123    0.8749    0.8932    119876\n","\n","    accuracy                         0.8810    361322\n","   macro avg     0.8814    0.8808    0.8807    361322\n","weighted avg     0.8813    0.8810    0.8808    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12557   838   107]\n"," [ 1103 11110  1112]\n"," [  610  1081 11629]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8800    0.9300    0.9043     13502\n","           1     0.8527    0.8338    0.8431     13325\n","           2     0.9051    0.8730    0.8888     13320\n","\n","    accuracy                         0.8792     40147\n","   macro avg     0.8793    0.8789    0.8787     40147\n","weighted avg     0.8793    0.8792    0.8789     40147\n","\n","\n","\n","Training starts for XGBR :\n","Total time taken to train XGBR is 132.5116834640503 sec.\n","\n","Confusion Matrix for Training data:\n","[[115967   4800    755]\n"," [  8392  98631  12901]\n"," [  3546  10680 105650]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9067    0.9543    0.9299    121522\n","           1     0.8643    0.8224    0.8429    119924\n","           2     0.8855    0.8813    0.8834    119876\n","\n","    accuracy                         0.8863    361322\n","   macro avg     0.8855    0.8860    0.8854    361322\n","weighted avg     0.8856    0.8863    0.8856    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12886   523    93]\n"," [  936 10932  1457]\n"," [  391  1155 11774]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9066    0.9544    0.9299     13502\n","           1     0.8669    0.8204    0.8430     13325\n","           2     0.8837    0.8839    0.8838     13320\n","\n","    accuracy                         0.8865     40147\n","   macro avg     0.8857    0.8862    0.8856     40147\n","weighted avg     0.8858    0.8865    0.8858     40147\n","\n","\n","\n","Training starts for CatBoost :\n","Total time taken to train CatBoost is 297.6857888698578 sec.\n","\n","Confusion Matrix for Training data:\n","[[113998   6407   1117]\n"," [ 11094  93986  14844]\n"," [  4230  12563 103083]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8815    0.9381    0.9089    121522\n","           1     0.8321    0.7837    0.8072    119924\n","           2     0.8659    0.8599    0.8629    119876\n","\n","    accuracy                         0.8609    361322\n","   macro avg     0.8598    0.8606    0.8597    361322\n","weighted avg     0.8599    0.8609    0.8599    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12654   715   133]\n"," [ 1229 10413  1683]\n"," [  486  1394 11440]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8806    0.9372    0.9080     13502\n","           1     0.8316    0.7815    0.8057     13325\n","           2     0.8630    0.8589    0.8609     13320\n","\n","    accuracy                         0.8595     40147\n","   macro avg     0.8584    0.8592    0.8582     40147\n","weighted avg     0.8585    0.8595    0.8585     40147\n","\n","\n","\n","Training starts for HistGradientBoosting :\n","Total time taken to train HistGradientBoosting is 113.92544984817505 sec.\n","\n","Confusion Matrix for Training data:\n","[[118112   2818    592]\n"," [  5097 103839  10988]\n"," [  1746  10456 107674]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9452    0.9719    0.9584    121522\n","           1     0.8867    0.8659    0.8761    119924\n","           2     0.9029    0.8982    0.9005    119876\n","\n","    accuracy                         0.9123    361322\n","   macro avg     0.9116    0.9120    0.9117    361322\n","weighted avg     0.9117    0.9123    0.9119    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[13118   316    68]\n"," [  563 11466  1296]\n"," [  221  1179 11920]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9436    0.9716    0.9574     13502\n","           1     0.8847    0.8605    0.8724     13325\n","           2     0.8973    0.8949    0.8961     13320\n","\n","    accuracy                         0.9093     40147\n","   macro avg     0.9085    0.9090    0.9086     40147\n","weighted avg     0.9087    0.9093    0.9088     40147\n","\n","\n","\n","Fold 2:\n","Training data: (361322, 318)\n","Validation data: (40147, 318)\n","\n","Training data y: (361322,)\n","Validation data y: (40147,)\n","\n","Training starts for MLP :\n","11292/11292 [==============================] - 44s 4ms/step - loss: 0.4089 - accuracy: 0.8317\n","Total time taken to train MLP is 142.15145349502563 sec.\n","\n","11292/11292 [==============================] - 18s 2ms/step\n","1255/1255 [==============================] - 2s 2ms/step\n","Confusion Matrix for Training data:\n","[[117626   2674   1222]\n"," [  7483  95016  17425]\n"," [  1644   7834 110398]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9280    0.9679    0.9475    121522\n","           1     0.9004    0.7923    0.8429    119924\n","           2     0.8555    0.9209    0.8870    119876\n","\n","    accuracy                         0.8941    361322\n","   macro avg     0.8946    0.8937    0.8925    361322\n","weighted avg     0.8948    0.8941    0.8927    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[13047   295   160]\n"," [  869 10428  2028]\n"," [  202   894 12224]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9241    0.9663    0.9448     13502\n","           1     0.8976    0.7826    0.8362     13325\n","           2     0.8482    0.9177    0.8816     13320\n","\n","    accuracy                         0.8892     40147\n","   macro avg     0.8900    0.8889    0.8875     40147\n","weighted avg     0.8901    0.8892    0.8878     40147\n","\n","\n","\n","Training starts for LogisticRegression :\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken to train LogisticRegression is 53.21032452583313 sec.\n","\n","Confusion Matrix for Training data:\n","[[93728 18382  9412]\n"," [24406 60573 34945]\n"," [15089 34089 70698]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7035    0.7713    0.7359    121522\n","           1     0.5358    0.5051    0.5200    119924\n","           2     0.6145    0.5898    0.6019    119876\n","\n","    accuracy                         0.6227    361322\n","   macro avg     0.6179    0.6220    0.6192    361322\n","weighted avg     0.6183    0.6227    0.6198    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[10422  2009  1071]\n"," [ 2692  6706  3927]\n"," [ 1713  3861  7746]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7029    0.7719    0.7358     13502\n","           1     0.5332    0.5033    0.5178     13325\n","           2     0.6078    0.5815    0.5944     13320\n","\n","    accuracy                         0.6196     40147\n","   macro avg     0.6147    0.6189    0.6160     40147\n","weighted avg     0.6150    0.6196    0.6165     40147\n","\n","\n","\n","Training starts for RandomForest :\n","Total time taken to train RandomForest is 160.78152513504028 sec.\n","\n","Confusion Matrix for Training data:\n","[[112449   8143    930]\n"," [  7971 100988  10965]\n"," [  3897   9695 106284]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9045    0.9253    0.9148    121522\n","           1     0.8499    0.8421    0.8460    119924\n","           2     0.8993    0.8866    0.8929    119876\n","\n","    accuracy                         0.8849    361322\n","   macro avg     0.8846    0.8847    0.8846    361322\n","weighted avg     0.8847    0.8849    0.8847    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12472   919   111]\n"," [  875 11134  1316]\n"," [  432  1111 11777]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9051    0.9237    0.9143     13502\n","           1     0.8458    0.8356    0.8407     13325\n","           2     0.8919    0.8842    0.8880     13320\n","\n","    accuracy                         0.8813     40147\n","   macro avg     0.8810    0.8811    0.8810     40147\n","weighted avg     0.8811    0.8813    0.8812     40147\n","\n","\n","\n","Training starts for LGBM :\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.457314 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 75012\n","[LightGBM] [Info] Number of data points in the train set: 361322, number of used features: 318\n","[LightGBM] [Info] Start training from score -1.089674\n","[LightGBM] [Info] Start training from score -1.102911\n","[LightGBM] [Info] Start training from score -1.103312\n","Total time taken to train LGBM is 77.28395795822144 sec.\n","\n","Confusion Matrix for Training data:\n","[[112901   6706   1915]\n"," [ 12063  89998  17863]\n"," [  5249  13852 100775]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8670    0.9291    0.8970    121522\n","           1     0.8140    0.7505    0.7810    119924\n","           2     0.8359    0.8407    0.8383    119876\n","\n","    accuracy                         0.8405    361322\n","   macro avg     0.8390    0.8401    0.8387    361322\n","weighted avg     0.8391    0.8405    0.8390    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12535   760   207]\n"," [ 1301  9989  2035]\n"," [  582  1526 11212]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8694    0.9284    0.8979     13502\n","           1     0.8138    0.7496    0.7804     13325\n","           2     0.8334    0.8417    0.8375     13320\n","\n","    accuracy                         0.8403     40147\n","   macro avg     0.8388    0.8399    0.8386     40147\n","weighted avg     0.8390    0.8403    0.8389     40147\n","\n","\n","\n","Training starts for ExtraTrees :\n","Total time taken to train ExtraTrees is 50.56843900680542 sec.\n","\n","Confusion Matrix for Training data:\n","[[112640   7929    953]\n"," [ 10727 100144   9053]\n"," [  5536   9638 104702]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8738    0.9269    0.8996    121522\n","           1     0.8508    0.8351    0.8428    119924\n","           2     0.9128    0.8734    0.8927    119876\n","\n","    accuracy                         0.8787    361322\n","   macro avg     0.8791    0.8785    0.8784    361322\n","weighted avg     0.8791    0.8787    0.8785    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12514   882   106]\n"," [ 1195 11003  1127]\n"," [  622  1113 11585]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8732    0.9268    0.8992     13502\n","           1     0.8465    0.8257    0.8360     13325\n","           2     0.9038    0.8697    0.8864     13320\n","\n","    accuracy                         0.8743     40147\n","   macro avg     0.8745    0.8741    0.8739     40147\n","weighted avg     0.8745    0.8743    0.8740     40147\n","\n","\n","\n","Training starts for XGBR :\n","Total time taken to train XGBR is 131.48508310317993 sec.\n","\n","Confusion Matrix for Training data:\n","[[115837   4951    734]\n"," [  8064  99182  12678]\n"," [  3467  10665 105744]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9095    0.9532    0.9308    121522\n","           1     0.8640    0.8270    0.8451    119924\n","           2     0.8874    0.8821    0.8848    119876\n","\n","    accuracy                         0.8877    361322\n","   macro avg     0.8870    0.8875    0.8869    361322\n","weighted avg     0.8871    0.8877    0.8871    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12862   556    84]\n"," [  875 10951  1499]\n"," [  388  1235 11697]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9106    0.9526    0.9311     13502\n","           1     0.8594    0.8218    0.8402     13325\n","           2     0.8808    0.8782    0.8795     13320\n","\n","    accuracy                         0.8845     40147\n","   macro avg     0.8836    0.8842    0.8836     40147\n","weighted avg     0.8837    0.8845    0.8838     40147\n","\n","\n","\n","Training starts for CatBoost :\n","Total time taken to train CatBoost is 304.0410943031311 sec.\n","\n","Confusion Matrix for Training data:\n","[[113276   6893   1353]\n"," [ 11239  93356  15329]\n"," [  4455  13177 102244]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8783    0.9321    0.9044    121522\n","           1     0.8231    0.7785    0.8001    119924\n","           2     0.8597    0.8529    0.8563    119876\n","\n","    accuracy                         0.8548    361322\n","   macro avg     0.8537    0.8545    0.8536    361322\n","weighted avg     0.8538    0.8548    0.8538    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12594   762   146]\n"," [ 1236 10286  1803]\n"," [  485  1460 11375]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8798    0.9328    0.9055     13502\n","           1     0.8224    0.7719    0.7963     13325\n","           2     0.8537    0.8540    0.8539     13320\n","\n","    accuracy                         0.8532     40147\n","   macro avg     0.8520    0.8529    0.8519     40147\n","weighted avg     0.8521    0.8532    0.8521     40147\n","\n","\n","\n","Training starts for HistGradientBoosting :\n","Total time taken to train HistGradientBoosting is 120.08893418312073 sec.\n","\n","Confusion Matrix for Training data:\n","[[117097   3704    721]\n"," [  5835 102495  11594]\n"," [  2213  10619 107044]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9357    0.9636    0.9494    121522\n","           1     0.8774    0.8547    0.8659    119924\n","           2     0.8968    0.8930    0.8949    119876\n","\n","    accuracy                         0.9040    361322\n","   macro avg     0.9033    0.9037    0.9034    361322\n","weighted avg     0.9034    0.9040    0.9036    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12988   434    80]\n"," [  648 11265  1412]\n"," [  249  1235 11836]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9354    0.9619    0.9485     13502\n","           1     0.8710    0.8454    0.8580     13325\n","           2     0.8881    0.8886    0.8883     13320\n","\n","    accuracy                         0.8989     40147\n","   macro avg     0.8981    0.8986    0.8983     40147\n","weighted avg     0.8983    0.8989    0.8985     40147\n","\n","\n","\n","Fold 3:\n","Training data: (361322, 318)\n","Validation data: (40147, 318)\n","\n","Training data y: (361322,)\n","Validation data y: (40147,)\n","\n","Training starts for MLP :\n","11292/11292 [==============================] - 49s 4ms/step - loss: 0.4089 - accuracy: 0.8316\n","Total time taken to train MLP is 168.22362112998962 sec.\n","\n","11292/11292 [==============================] - 19s 2ms/step\n","1255/1255 [==============================] - 2s 2ms/step\n","Confusion Matrix for Training data:\n","[[117581   3058    883]\n"," [  8712  96784  14428]\n"," [  2213  10002 107661]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9150    0.9676    0.9405    121522\n","           1     0.8811    0.8070    0.8424    119924\n","           2     0.8755    0.8981    0.8867    119876\n","\n","    accuracy                         0.8912    361322\n","   macro avg     0.8905    0.8909    0.8899    361322\n","weighted avg     0.8906    0.8912    0.8901    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[13055   340   107]\n"," [  999 10650  1676]\n"," [  280  1224 11816]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9108    0.9669    0.9380     13502\n","           1     0.8720    0.7992    0.8340     13325\n","           2     0.8689    0.8871    0.8779     13320\n","\n","    accuracy                         0.8848     40147\n","   macro avg     0.8839    0.8844    0.8833     40147\n","weighted avg     0.8840    0.8848    0.8835     40147\n","\n","\n","\n","Training starts for LogisticRegression :\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken to train LogisticRegression is 54.87801909446716 sec.\n","\n","Confusion Matrix for Training data:\n","[[93733 18284  9505]\n"," [24321 60524 35079]\n"," [15087 34066 70723]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7040    0.7713    0.7361    121522\n","           1     0.5362    0.5047    0.5200    119924\n","           2     0.6133    0.5900    0.6014    119876\n","\n","    accuracy                         0.6227    361322\n","   macro avg     0.6179    0.6220    0.6192    361322\n","weighted avg     0.6182    0.6227    0.6197    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[10361  2036  1105]\n"," [ 2702  6751  3872]\n"," [ 1666  3798  7856]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7034    0.7674    0.7340     13502\n","           1     0.5364    0.5066    0.5211     13325\n","           2     0.6122    0.5898    0.6008     13320\n","\n","    accuracy                         0.6219     40147\n","   macro avg     0.6173    0.6213    0.6186     40147\n","weighted avg     0.6177    0.6219    0.6191     40147\n","\n","\n","\n","Training starts for RandomForest :\n","Total time taken to train RandomForest is 156.92953324317932 sec.\n","\n","Confusion Matrix for Training data:\n","[[113321   7367    834]\n"," [  8710 100303  10911]\n"," [  3750   9182 106944]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9009    0.9325    0.9165    121522\n","           1     0.8584    0.8364    0.8472    119924\n","           2     0.9010    0.8921    0.8966    119876\n","\n","    accuracy                         0.8872    361322\n","   macro avg     0.8868    0.8870    0.8868    361322\n","weighted avg     0.8868    0.8872    0.8869    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12610   797    95]\n"," [  965 11041  1319]\n"," [  444  1137 11739]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8995    0.9339    0.9164     13502\n","           1     0.8509    0.8286    0.8396     13325\n","           2     0.8925    0.8813    0.8869     13320\n","\n","    accuracy                         0.8815     40147\n","   macro avg     0.8810    0.8813    0.8810     40147\n","weighted avg     0.8811    0.8815    0.8811     40147\n","\n","\n","\n","Training starts for LGBM :\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.405509 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 75028\n","[LightGBM] [Info] Number of data points in the train set: 361322, number of used features: 318\n","[LightGBM] [Info] Start training from score -1.089674\n","[LightGBM] [Info] Start training from score -1.102911\n","[LightGBM] [Info] Start training from score -1.103312\n","Total time taken to train LGBM is 77.21725344657898 sec.\n","\n","Confusion Matrix for Training data:\n","[[112312   7342   1868]\n"," [ 11286  91208  17430]\n"," [  4737  13703 101436]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8751    0.9242    0.8990    121522\n","           1     0.8125    0.7605    0.7857    119924\n","           2     0.8402    0.8462    0.8432    119876\n","\n","    accuracy                         0.8440    361322\n","   macro avg     0.8426    0.8436    0.8426    361322\n","weighted avg     0.8428    0.8440    0.8429    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12489   807   206]\n"," [ 1261 10045  2019]\n"," [  583  1587 11150]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8713    0.9250    0.8974     13502\n","           1     0.8075    0.7538    0.7798     13325\n","           2     0.8336    0.8371    0.8354     13320\n","\n","    accuracy                         0.8390     40147\n","   macro avg     0.8375    0.8386    0.8375     40147\n","weighted avg     0.8377    0.8390    0.8378     40147\n","\n","\n","\n","Training starts for ExtraTrees :\n","Total time taken to train ExtraTrees is 48.2248740196228 sec.\n","\n","Confusion Matrix for Training data:\n","[[112574   8121    827]\n"," [ 10533 101000   8391]\n"," [  5392   9927 104557]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8761    0.9264    0.9005    121522\n","           1     0.8484    0.8422    0.8453    119924\n","           2     0.9190    0.8722    0.8950    119876\n","\n","    accuracy                         0.8805    361322\n","   macro avg     0.8811    0.8803    0.8803    361322\n","weighted avg     0.8811    0.8805    0.8804    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12549   858    95]\n"," [ 1178 11136  1011]\n"," [  633  1174 11513]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8739    0.9294    0.9008     13502\n","           1     0.8457    0.8357    0.8407     13325\n","           2     0.9124    0.8643    0.8877     13320\n","\n","    accuracy                         0.8767     40147\n","   macro avg     0.8773    0.8765    0.8764     40147\n","weighted avg     0.8773    0.8767    0.8765     40147\n","\n","\n","\n","Training starts for XGBR :\n","Total time taken to train XGBR is 138.54485988616943 sec.\n","\n","Confusion Matrix for Training data:\n","[[116153   4596    773]\n"," [  8397  98418  13109]\n"," [  3785  10648 105443]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9051    0.9558    0.9298    121522\n","           1     0.8659    0.8207    0.8427    119924\n","           2     0.8837    0.8796    0.8816    119876\n","\n","    accuracy                         0.8857    361322\n","   macro avg     0.8849    0.8854    0.8847    361322\n","weighted avg     0.8850    0.8857    0.8849    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12889   530    83]\n"," [  974 10844  1507]\n"," [  468  1270 11582]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8994    0.9546    0.9262     13502\n","           1     0.8576    0.8138    0.8351     13325\n","           2     0.8793    0.8695    0.8744     13320\n","\n","    accuracy                         0.8796     40147\n","   macro avg     0.8788    0.8793    0.8786     40147\n","weighted avg     0.8789    0.8796    0.8788     40147\n","\n","\n","\n","Training starts for CatBoost :\n","Total time taken to train CatBoost is 295.54795360565186 sec.\n","\n","Confusion Matrix for Training data:\n","[[113703   6620   1199]\n"," [ 10895  93409  15620]\n"," [  4194  12700 102982]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8828    0.9357    0.9085    121522\n","           1     0.8286    0.7789    0.8030    119924\n","           2     0.8596    0.8591    0.8593    119876\n","\n","    accuracy                         0.8582    361322\n","   macro avg     0.8570    0.8579    0.8569    361322\n","weighted avg     0.8571    0.8582    0.8572    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12667   688   147]\n"," [ 1240 10301  1784]\n"," [  494  1470 11356]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8796    0.9382    0.9079     13502\n","           1     0.8268    0.7731    0.7990     13325\n","           2     0.8547    0.8526    0.8536     13320\n","\n","    accuracy                         0.8550     40147\n","   macro avg     0.8537    0.8546    0.8535     40147\n","weighted avg     0.8538    0.8550    0.8538     40147\n","\n","\n","\n","Training starts for HistGradientBoosting :\n","Total time taken to train HistGradientBoosting is 112.7534818649292 sec.\n","\n","Confusion Matrix for Training data:\n","[[117956   2952    614]\n"," [  5504 103330  11090]\n"," [  1839  10457 107580]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9414    0.9707    0.9558    121522\n","           1     0.8851    0.8616    0.8732    119924\n","           2     0.9019    0.8974    0.8996    119876\n","\n","    accuracy                         0.9102    361322\n","   macro avg     0.9095    0.9099    0.9096    361322\n","weighted avg     0.9096    0.9102    0.9098    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[13097   332    73]\n"," [  623 11419  1283]\n"," [  240  1259 11821]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9382    0.9700    0.9538     13502\n","           1     0.8777    0.8570    0.8672     13325\n","           2     0.8971    0.8875    0.8923     13320\n","\n","    accuracy                         0.9051     40147\n","   macro avg     0.9043    0.9048    0.9044     40147\n","weighted avg     0.9045    0.9051    0.9046     40147\n","\n","\n","\n","Fold 4:\n","Training data: (361322, 318)\n","Validation data: (40147, 318)\n","\n","Training data y: (361322,)\n","Validation data y: (40147,)\n","\n","Training starts for MLP :\n","11292/11292 [==============================] - 44s 4ms/step - loss: 0.4060 - accuracy: 0.8333\n","Total time taken to train MLP is 104.8456654548645 sec.\n","\n","11292/11292 [==============================] - 19s 2ms/step\n","1255/1255 [==============================] - 2s 2ms/step\n","Confusion Matrix for Training data:\n","[[118293   2470    759]\n"," [  7829  98353  13742]\n"," [  2500  10569 106807]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9197    0.9734    0.9458    121522\n","           1     0.8829    0.8201    0.8504    119924\n","           2     0.8805    0.8910    0.8857    119876\n","\n","    accuracy                         0.8952    361322\n","   macro avg     0.8944    0.8948    0.8940    361322\n","weighted avg     0.8945    0.8952    0.8942    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[13103   299   100]\n"," [  947 10786  1592]\n"," [  263  1231 11826]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9155    0.9704    0.9422     13502\n","           1     0.8758    0.8095    0.8413     13325\n","           2     0.8748    0.8878    0.8813     13320\n","\n","    accuracy                         0.8896     40147\n","   macro avg     0.8887    0.8892    0.8883     40147\n","weighted avg     0.8888    0.8896    0.8885     40147\n","\n","\n","\n","Training starts for LogisticRegression :\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken to train LogisticRegression is 53.49441075325012 sec.\n","\n","Confusion Matrix for Training data:\n","[[93759 18327  9436]\n"," [24336 60689 34899]\n"," [15104 34082 70690]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7039    0.7715    0.7362    121522\n","           1     0.5366    0.5061    0.5209    119924\n","           2     0.6146    0.5897    0.6019    119876\n","\n","    accuracy                         0.6231    361322\n","   macro avg     0.6184    0.6224    0.6196    361322\n","weighted avg     0.6187    0.6231    0.6202    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[10422  2044  1036]\n"," [ 2754  6745  3826]\n"," [ 1657  3848  7815]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7026    0.7719    0.7356     13502\n","           1     0.5338    0.5062    0.5196     13325\n","           2     0.6165    0.5867    0.6012     13320\n","\n","    accuracy                         0.6223     40147\n","   macro avg     0.6176    0.6216    0.6188     40147\n","weighted avg     0.6180    0.6223    0.6193     40147\n","\n","\n","\n","Training starts for RandomForest :\n","Total time taken to train RandomForest is 156.97440576553345 sec.\n","\n","Confusion Matrix for Training data:\n","[[112689   7875    958]\n"," [  7955 100713  11256]\n"," [  3839   9265 106772]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9053    0.9273    0.9162    121522\n","           1     0.8546    0.8398    0.8471    119924\n","           2     0.8973    0.8907    0.8940    119876\n","\n","    accuracy                         0.8861    361322\n","   macro avg     0.8857    0.8859    0.8858    361322\n","weighted avg     0.8858    0.8861    0.8859    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12497   888   117]\n"," [  929 11102  1294]\n"," [  412  1062 11846]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9031    0.9256    0.9142     13502\n","           1     0.8506    0.8332    0.8418     13325\n","           2     0.8936    0.8893    0.8914     13320\n","\n","    accuracy                         0.8829     40147\n","   macro avg     0.8824    0.8827    0.8825     40147\n","weighted avg     0.8825    0.8829    0.8826     40147\n","\n","\n","\n","Training starts for LGBM :\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.556209 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 75071\n","[LightGBM] [Info] Number of data points in the train set: 361322, number of used features: 318\n","[LightGBM] [Info] Start training from score -1.089674\n","[LightGBM] [Info] Start training from score -1.102911\n","[LightGBM] [Info] Start training from score -1.103312\n","Total time taken to train LGBM is 77.53495287895203 sec.\n","\n","Confusion Matrix for Training data:\n","[[111797   7979   1746]\n"," [ 11484  90884  17556]\n"," [  4832  14053 100991]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8726    0.9200    0.8957    121522\n","           1     0.8049    0.7578    0.7807    119924\n","           2     0.8395    0.8425    0.8410    119876\n","\n","    accuracy                         0.8404    361322\n","   macro avg     0.8390    0.8401    0.8391    361322\n","weighted avg     0.8392    0.8404    0.8394    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12355   941   206]\n"," [ 1316 10038  1971]\n"," [  525  1587 11208]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8703    0.9150    0.8921     13502\n","           1     0.7988    0.7533    0.7754     13325\n","           2     0.8374    0.8414    0.8394     13320\n","\n","    accuracy                         0.8369     40147\n","   macro avg     0.8355    0.8366    0.8356     40147\n","weighted avg     0.8357    0.8369    0.8359     40147\n","\n","\n","\n","Training starts for ExtraTrees :\n","Total time taken to train ExtraTrees is 47.55224132537842 sec.\n","\n","Confusion Matrix for Training data:\n","[[112419   8001   1102]\n"," [ 10058 101189   8677]\n"," [  5271   9866 104739]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8800    0.9251    0.9020    121522\n","           1     0.8499    0.8438    0.8468    119924\n","           2     0.9146    0.8737    0.8937    119876\n","\n","    accuracy                         0.8811    361322\n","   macro avg     0.8815    0.8809    0.8808    361322\n","weighted avg     0.8815    0.8811    0.8809    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12477   899   126]\n"," [ 1131 11141  1053]\n"," [  572  1103 11645]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8799    0.9241    0.9015     13502\n","           1     0.8477    0.8361    0.8418     13325\n","           2     0.9081    0.8742    0.8908     13320\n","\n","    accuracy                         0.8783     40147\n","   macro avg     0.8785    0.8781    0.8780     40147\n","weighted avg     0.8785    0.8783    0.8781     40147\n","\n","\n","\n","Training starts for XGBR :\n","Total time taken to train XGBR is 131.96528673171997 sec.\n","\n","Confusion Matrix for Training data:\n","[[115739   5087    696]\n"," [  8109  98757  13058]\n"," [  3445  10972 105459]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9092    0.9524    0.9303    121522\n","           1     0.8601    0.8235    0.8414    119924\n","           2     0.8846    0.8797    0.8822    119876\n","\n","    accuracy                         0.8855    361322\n","   macro avg     0.8847    0.8852    0.8846    361322\n","weighted avg     0.8848    0.8855    0.8848    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12815   593    94]\n"," [  996 10885  1444]\n"," [  369  1259 11692]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9037    0.9491    0.9259     13502\n","           1     0.8546    0.8169    0.8353     13325\n","           2     0.8837    0.8778    0.8808     13320\n","\n","    accuracy                         0.8816     40147\n","   macro avg     0.8807    0.8813    0.8806     40147\n","weighted avg     0.8808    0.8816    0.8808     40147\n","\n","\n","\n","Training starts for CatBoost :\n","Total time taken to train CatBoost is 294.3589012622833 sec.\n","\n","Confusion Matrix for Training data:\n","[[113276   7045   1201]\n"," [ 11080  93457  15387]\n"," [  4530  12870 102476]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8789    0.9321    0.9047    121522\n","           1     0.8243    0.7793    0.8012    119924\n","           2     0.8607    0.8549    0.8578    119876\n","\n","    accuracy                         0.8558    361322\n","   macro avg     0.8546    0.8554    0.8546    361322\n","weighted avg     0.8547    0.8558    0.8548    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12544   796   162]\n"," [ 1258 10353  1714]\n"," [  476  1453 11391]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8786    0.9290    0.9031     13502\n","           1     0.8215    0.7770    0.7986     13325\n","           2     0.8586    0.8552    0.8569     13320\n","\n","    accuracy                         0.8541     40147\n","   macro avg     0.8529    0.8537    0.8529     40147\n","weighted avg     0.8530    0.8541    0.8531     40147\n","\n","\n","\n","Training starts for HistGradientBoosting :\n","Total time taken to train HistGradientBoosting is 57.095035791397095 sec.\n","\n","Confusion Matrix for Training data:\n","[[113353   6790   1379]\n"," [  9793  93924  16207]\n"," [  4364  13868 101644]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8890    0.9328    0.9103    121522\n","           1     0.8197    0.7832    0.8010    119924\n","           2     0.8525    0.8479    0.8502    119876\n","\n","    accuracy                         0.8550    361322\n","   macro avg     0.8537    0.8546    0.8539    361322\n","weighted avg     0.8539    0.8550    0.8541    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12549   798   155]\n"," [ 1147 10411  1767]\n"," [  478  1589 11253]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8854    0.9294    0.9069     13502\n","           1     0.8135    0.7813    0.7971     13325\n","           2     0.8541    0.8448    0.8494     13320\n","\n","    accuracy                         0.8522     40147\n","   macro avg     0.8510    0.8519    0.8511     40147\n","weighted avg     0.8511    0.8522    0.8514     40147\n","\n","\n","\n","Fold 5:\n","Training data: (361322, 318)\n","Validation data: (40147, 318)\n","\n","Training data y: (361322,)\n","Validation data y: (40147,)\n","\n","Training starts for MLP :\n","11292/11292 [==============================] - 44s 4ms/step - loss: 0.4054 - accuracy: 0.8336\n","Total time taken to train MLP is 129.47706127166748 sec.\n","\n","11292/11292 [==============================] - 19s 2ms/step\n","1255/1255 [==============================] - 3s 2ms/step\n","Confusion Matrix for Training data:\n","[[116429   4189    904]\n"," [  6040  99186  14698]\n"," [  1797   9583 108496]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9369    0.9581    0.9474    121522\n","           1     0.8781    0.8271    0.8518    119924\n","           2     0.8743    0.9051    0.8894    119876\n","\n","    accuracy                         0.8970    361322\n","   macro avg     0.8964    0.8967    0.8962    361322\n","weighted avg     0.8966    0.8970    0.8964    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12894   477   131]\n"," [  720 10891  1714]\n"," [  218  1223 11879]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9322    0.9550    0.9434     13502\n","           1     0.8650    0.8173    0.8405     13325\n","           2     0.8656    0.8918    0.8785     13320\n","\n","    accuracy                         0.8883     40147\n","   macro avg     0.8876    0.8880    0.8875     40147\n","weighted avg     0.8878    0.8883    0.8877     40147\n","\n","\n","\n","Training starts for LogisticRegression :\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Total time taken to train LogisticRegression is 54.19049406051636 sec.\n","\n","Confusion Matrix for Training data:\n","[[93750 18329  9443]\n"," [24427 60616 34881]\n"," [15115 34115 70646]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7033    0.7715    0.7358    121522\n","           1     0.5361    0.5055    0.5203    119924\n","           2     0.6145    0.5893    0.6016    119876\n","\n","    accuracy                         0.6227    361322\n","   macro avg     0.6180    0.6221    0.6193    361322\n","weighted avg     0.6184    0.6227    0.6198    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[10376  2066  1060]\n"," [ 2684  6661  3980]\n"," [ 1706  3764  7850]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.7027    0.7685    0.7341     13502\n","           1     0.5333    0.4999    0.5160     13325\n","           2     0.6090    0.5893    0.5990     13320\n","\n","    accuracy                         0.6199     40147\n","   macro avg     0.6150    0.6192    0.6164     40147\n","weighted avg     0.6154    0.6199    0.6169     40147\n","\n","\n","\n","Training starts for RandomForest :\n","Total time taken to train RandomForest is 154.9387993812561 sec.\n","\n","Confusion Matrix for Training data:\n","[[113250   7431    841]\n"," [  8015 100799  11110]\n"," [  3741   9478 106657]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9060    0.9319    0.9188    121522\n","           1     0.8563    0.8405    0.8484    119924\n","           2     0.8992    0.8897    0.8945    119876\n","\n","    accuracy                         0.8876    361322\n","   macro avg     0.8872    0.8874    0.8872    361322\n","weighted avg     0.8873    0.8876    0.8873    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12509   894    99]\n"," [  860 11125  1340]\n"," [  431  1136 11753]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9064    0.9265    0.9163     13502\n","           1     0.8457    0.8349    0.8403     13325\n","           2     0.8909    0.8824    0.8866     13320\n","\n","    accuracy                         0.8814     40147\n","   macro avg     0.8810    0.8812    0.8811     40147\n","weighted avg     0.8811    0.8814    0.8812     40147\n","\n","\n","\n","Training starts for LGBM :\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.324638 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 75073\n","[LightGBM] [Info] Number of data points in the train set: 361322, number of used features: 318\n","[LightGBM] [Info] Start training from score -1.089674\n","[LightGBM] [Info] Start training from score -1.102911\n","[LightGBM] [Info] Start training from score -1.103312\n","Total time taken to train LGBM is 76.42411661148071 sec.\n","\n","Confusion Matrix for Training data:\n","[[113158   6772   1592]\n"," [ 12388  89082  18454]\n"," [  4790  13339 101747]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8682    0.9312    0.8986    121522\n","           1     0.8158    0.7428    0.7776    119924\n","           2     0.8354    0.8488    0.8420    119876\n","\n","    accuracy                         0.8413    361322\n","   macro avg     0.8398    0.8409    0.8394    361322\n","weighted avg     0.8399    0.8413    0.8397    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12493   814   195]\n"," [ 1386  9930  2009]\n"," [  550  1519 11251]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8658    0.9253    0.8946     13502\n","           1     0.8098    0.7452    0.7761     13325\n","           2     0.8362    0.8447    0.8404     13320\n","\n","    accuracy                         0.8388     40147\n","   macro avg     0.8373    0.8384    0.8370     40147\n","weighted avg     0.8374    0.8388    0.8373     40147\n","\n","\n","\n","Training starts for ExtraTrees :\n","Total time taken to train ExtraTrees is 51.49859023094177 sec.\n","\n","Confusion Matrix for Training data:\n","[[112663   7865    994]\n"," [  9886 101450   8588]\n"," [  5154   9546 105176]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8822    0.9271    0.9041    121522\n","           1     0.8535    0.8460    0.8497    119924\n","           2     0.9165    0.8774    0.8965    119876\n","\n","    accuracy                         0.8837    361322\n","   macro avg     0.8841    0.8835    0.8834    361322\n","weighted avg     0.8841    0.8837    0.8835    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12450   932   120]\n"," [ 1089 11192  1044]\n"," [  635  1136 11549]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8784    0.9221    0.8997     13502\n","           1     0.8440    0.8399    0.8420     13325\n","           2     0.9084    0.8670    0.8873     13320\n","\n","    accuracy                         0.8766     40147\n","   macro avg     0.8770    0.8764    0.8763     40147\n","weighted avg     0.8770    0.8766    0.8764     40147\n","\n","\n","\n","Training starts for XGBR :\n","Total time taken to train XGBR is 133.3958842754364 sec.\n","\n","Confusion Matrix for Training data:\n","[[115675   5270    577]\n"," [  8226  99213  12485]\n"," [  3536  10521 105819]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9077    0.9519    0.9293    121522\n","           1     0.8627    0.8273    0.8446    119924\n","           2     0.8901    0.8827    0.8864    119876\n","\n","    accuracy                         0.8876    361322\n","   macro avg     0.8868    0.8873    0.8868    361322\n","weighted avg     0.8869    0.8876    0.8870    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12784   641    77]\n"," [  911 11006  1408]\n"," [  431  1238 11651]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9050    0.9468    0.9254     13502\n","           1     0.8542    0.8260    0.8398     13325\n","           2     0.8870    0.8747    0.8808     13320\n","\n","    accuracy                         0.8828     40147\n","   macro avg     0.8820    0.8825    0.8820     40147\n","weighted avg     0.8821    0.8828    0.8822     40147\n","\n","\n","\n","Training starts for CatBoost :\n","Total time taken to train CatBoost is 296.0538034439087 sec.\n","\n","Confusion Matrix for Training data:\n","[[113369   6835   1318]\n"," [ 10891  94244  14789]\n"," [  4396  12640 102840]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8812    0.9329    0.9063    121522\n","           1     0.8287    0.7859    0.8067    119924\n","           2     0.8646    0.8579    0.8612    119876\n","\n","    accuracy                         0.8592    361322\n","   macro avg     0.8582    0.8589    0.8581    361322\n","weighted avg     0.8583    0.8592    0.8583    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[12526   806   170]\n"," [ 1205 10456  1664]\n"," [  498  1473 11349]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.8803    0.9277    0.9034     13502\n","           1     0.8210    0.7847    0.8025     13325\n","           2     0.8609    0.8520    0.8564     13320\n","\n","    accuracy                         0.8551     40147\n","   macro avg     0.8541    0.8548    0.8541     40147\n","weighted avg     0.8542    0.8551    0.8543     40147\n","\n","\n","\n","Training starts for HistGradientBoosting :\n","Total time taken to train HistGradientBoosting is 113.63072943687439 sec.\n","\n","Confusion Matrix for Training data:\n","[[118027   2769    726]\n"," [  5220 103402  11302]\n"," [  2005  10181 107690]]\n","\n","Classification Report for Training data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9423    0.9712    0.9566    121522\n","           1     0.8887    0.8622    0.8753    119924\n","           2     0.8995    0.8983    0.8989    119876\n","\n","    accuracy                         0.9109    361322\n","   macro avg     0.9102    0.9106    0.9103    361322\n","weighted avg     0.9103    0.9109    0.9105    361322\n","\n","\n","\n","***************************************************\n","\n","\n","Confusion Matrix for Validation data:\n","[[13052   367    83]\n"," [  603 11373  1349]\n"," [  231  1227 11862]]\n","\n","Classification Report for Validation data:\n","              precision    recall  f1-score   support\n","\n","           0     0.9399    0.9667    0.9531     13502\n","           1     0.8771    0.8535    0.8651     13325\n","           2     0.8923    0.8905    0.8914     13320\n","\n","    accuracy                         0.9039     40147\n","   macro avg     0.9031    0.9036    0.9032     40147\n","weighted avg     0.9033    0.9039    0.9034     40147\n","\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"W4H89ViUMtTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-8y1sUBXlFf6"},"execution_count":null,"outputs":[]}]}